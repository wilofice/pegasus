Guide d'Implémentation Détaillé – Projet Pegasus
Note de l'Auteur : Ce document est une proposition de plan de mise en œuvre technique. Il est conçu pour être un guide détaillé, mais il devra être adapté en fonction des défis techniques et des découvertes que nous ferons en cours de route. La flexibilité sera la clé de notre succès.

Partie 1 : Guideline d'Implémentation du Data Pipeline
Objectif : Mettre en place l'infrastructure et le code pour une pipeline de traitement de données résiliente et évolutive qui alimente notre système à double mémoire.

Phase 1 : La Fondation Résiliente (Semaines 1-4)
Tâche 1.1 : Mise en Place de l'Infrastructure via Docker Compose

Action : Créez un fichier docker-compose.yml à la racine du projet pegasus/. Ce fichier orchestrera tous nos services d'arrière-plan.

Contenu du docker-compose.yml :

Un service redis basé sur l'image officielle redis:alpine.

Un service neo4j basé sur l'image neo4j:latest, en exposant les ports 7474 (interface web) et 7687 (Bolt driver).

Un service chromadb (si nous choisissons de le conteneuriser, sinon il sera local au worker).

Un service pipeline-worker que nous définirons plus tard.

Test : Exécutez docker-compose up. Vous devriez pouvoir accéder à l'interface web de Neo4j sur http://localhost:7474.

Tâche 1.2 : Développement du Worker avec Celery et Redis

Action : Dans le dossier data_pipeline/, nous allons utiliser Celery, le standard de l'industrie pour les tâches asynchrones en Python.

Fichier celery_app.py : Configurez Celery pour utiliser Redis comme "broker" (l'intermédiaire qui gère la file d'attente).

Fichier tasks.py : Définissez la tâche principale : @celery.task def process_file_task(filepath): .... C'est ici que résidera la logique de traitement.

Test : Créez un script de test qui ajoute un chemin de fichier à la file d'attente Celery et vérifiez que le worker le reçoit.

Tâche 1.3 : Implémentation du Traitement de Fichier dans le Worker

Action : Dans la fonction process_file_task, implémentez la chaîne de traitement :

Extraction de Texte : Utilisez des fonctions distinctes pour gérer les .mp3 (avec Whisper), les .txt, et les .eml (avec eml_parser).

Chunking : Implémentez la stratégie de "fixed-size with overlap".

NER (spaCy) : Chargez un modèle spaCy (ex: fr_core_news_md). Pour chaque chunk, itérez sur doc.ents pour extraire les entités (PER, LOC, ORG).

Test : Testez unitairement chaque fonction d'extraction et de traitement avec nos fichiers de test.

Tâche 1.4 : Implémentation de l'Ingestion Double-DB

Action : Toujours dans la tâche Celery, après le traitement :

ChromaDB : Connectez-vous au client ChromaDB. Vectorisez chaque chunk (avec sentence-transformers) et ajoutez-le à la collection avec ses métadonnées (source, date).

Neo4j : Utilisez le driver officiel neo4j pour Python. Pour chaque entité unique extraite :

Exécutez une requête Cypher MERGE (n:Entity {name: $name, type: $type}) pour créer le nœud s'il n'existe pas.

Créez une relation MERGE (e:Entity {name: $entity_name})-[:MENTIONED_IN]->(d:Document {name: $source_file}).

Test : Après avoir traité un fichier, utilisez l'interface web de Neo4j et un script Python pour vérifier que les nœuds et les relations ont été correctement créés dans les deux bases de données.

Partie 2 : Guideline d'Implémentation du Backend
Objectif : Construire le cerveau de Pegasus, capable de raisonner en utilisant le système à double mémoire et d'être étendu via des plugins.

Phase 2 : Récupération Intelligente (Semaines 5-7)
Tâche 2.1 : Développement du ContextAggregator

Action : Dans backend/core/orchestrator.py, créez la classe ContextAggregator.

Logique de la méthode build_context(query) :

Vector Search : Vectorisez la query et faites une recherche de similarité dans ChromaDB pour obtenir les k chunks les plus pertinents.

Entity Extraction from Query : Appliquez NER sur la query de l'utilisateur pour identifier les entités clés qu'il mentionne.

Graph Search : Pour chaque entité trouvée dans les chunks pertinents (de l'étape 1) et dans la query (étape 2), exécutez une requête Cypher dans Neo4j pour trouver les nœuds directement connectés. Par exemple : MATCH (e:Entity {name: $entity_name})-[r]-(related_node) RETURN related_node.

Synthèse : Formatez les chunks sémantiques et les informations relationnelles du graphe en un contexte textuel clair et concis, prêt à être inséré dans le prompt du LLM.

Test : Créez des tests unitaires qui appellent build_context avec différentes requêtes et vérifient que le contexte généré est pertinent et bien structuré.

Phase 3 : L'Écosystème de Plugins (Semaines 8-10)
Tâche 3.1 : Implémentation du PluginManager

Action : Dans backend/core/, créez plugin_manager.py.

Structure :

Une classe PluginManager avec un dictionnaire self.plugins = {}.

Une méthode register(plugin_name, plugin_instance).

Une méthode execute(plugin_name, context) qui appelle la méthode run du plugin correspondant.

Intégration : L'orchestrateur principal de chat vérifiera si le message de l'utilisateur correspond à une commande de plugin (ex: commence par /review). Si c'est le cas, il appellera le PluginManager au lieu du flux de RAG normal.

Tâche 3.2 : Développement du Plugin "Review & Reflection"

Action : Créez un nouveau dossier backend/plugins/. À l'intérieur, review_plugin.py.

Structure de la classe ReviewPlugin :

Une méthode run(timeframe="weekly", topic=None) qui sera appelée par le manager.

Cette méthode effectuera une large recherche dans ChromaDB (filtrée par date).

Elle enverra la collection de textes pertinents à un LLM avec un prompt spécifiquement conçu pour la synthèse et l'identification de thèmes.

Elle formatera la réponse du LLM en Markdown structuré.

Enregistrement : Dans main.py, instanciez le plugin et enregistrez-le auprès du PluginManager.

Test : Créez un endpoint API de test /plugins/review/run qui appelle directement ce plugin et vérifiez la qualité de la synthèse produite.

Partie 3 : Guideline d'Implémentation du Frontend (Flutter)
Objectif : Créer une interface utilisateur réactive, agréable et capable de dialoguer avec les capacités avancées du backend.

Tâche 3.1 : Mise en Place de la Gestion d'État avec Riverpod

Action : Structurez l'état du ChatScreen.

Provider : Utilisez un AsyncNotifierProvider pour gérer l'état de la conversation. L'état (state) sera un objet qui contient la liste des messages, un statut de chargement (isLoading), et une éventuelle erreur.

Logique : La méthode sendMessage du notifier mettra l'état en isLoading, appellera le client API, puis mettra à jour l'état avec la réponse ou une erreur.

Tâche 3.2 : Développement du Client API (Dio)

Action : Dans lib/api/pegasus_api_client.dart, utilisez le package dio pour une gestion avancée des requêtes HTTP.

Méthodes :

Future<ChatMessage> postMessage(String text) : Envoie le message au backend et décode la réponse.

Future<String> startReview(String topic) : Appelle l'endpoint du plugin de revue et retourne la synthèse en Markdown.

Tâche 3.3 : Connexion UI et Logique

Action : Dans le ChatScreen, utilisez un ConsumerWidget pour écouter les changements du chatProvider.

Affichage :

Quand l'état est isLoading, affichez un indicateur de chargement (un widget avec des points qui clignotent).

Quand l'état contient des données, affichez la liste des messages.

Quand l'état est en erreur, affichez un message d'erreur.

Interaction : Le bouton "Envoyer" dans le MessageComposer appellera la méthode sendMessage du provider.

Tâche 3.4 : Affichage du Contenu Riche (Markdown)

Action : Pour afficher les synthèses formatées du plugin de revue.

Package : Utilisez le package flutter_markdown pour transformer le texte Markdown renvoyé par l'API en widgets Flutter joliment formatés (titres, listes, gras, etc.).

Test : Créez une vue de test qui prend une chaîne de caractères Markdown et vérifie qu'elle est correctement rendue à l'écran.