Cahier des Spécifications Techniques
Projet : Pegasus
Version : 1.0
Date : 22 juin 2025

1. Principes d'Architecture
1.1. Vision Technique
Pegasus est une application personnelle, non-commerciale, avec une architecture "mobile-first". Le système est conçu autour d'un serveur de données personnel et privé, qui sert de mémoire à long terme pour une Intelligence Artificielle conversationnelle. La sécurité, la confidentialité et la souveraineté des données de l'utilisateur sont les piliers de cette architecture.

1.2. Schéma d'Architecture Générale
Le système Pegasus se compose de quatre blocs principaux :

Frontend (Applications Client) : L'interface de chat (texte/voix) sur mobile et web.

Backend (Serveur Applicatif) : Le cerveau de Pegasus, qui orchestre la conversation.

Serveur de Données & Base Vectorielle : La mémoire personnelle et le contexte de l'utilisateur.

Service LLM Externe : Le modèle de langage qui génère les réponses.


Légende : 1. L'Utilisateur interagit avec le Frontend. 2. Le Frontend envoie la requête au Backend. 3. Le Backend interroge la Base Vectorielle pour du contexte. 4. Le Backend envoie la requête + contexte au LLM. 5. Le Backend reçoit la réponse et la renvoie au Frontend.

2. Spécifications des Composants
2.1. Frontend (Application Mobile & Web)
Framework Mobile : React Native. Permet de développer une seule base de code pour iOS et Android, idéal pour une approche "mobile-first". Offre un accès natif aux fonctionnalités comme le micro.

Framework Web : React.js. Partage la même logique de composants que React Native, permettant de réutiliser une partie du code (logique métier, gestion d'état) entre le web et le mobile.

Interface de Chat : Utilisation de bibliothèques comme react-native-gifted-chat pour une base solide. L'interface devra gérer l'affichage des messages texte et un bouton pour l'enregistrement vocal.

Fonctionnalités Voix :

Speech-to-Text (STT) : Utilisation des API natives d'iOS et Android pour une transcription vocale de haute qualité et à faible latence, directement sur l'appareil.

Text-to-Speech (TTS) : Utilisation des voix natives des plateformes pour lire les réponses de Pegasus.

Communication Backend : Les requêtes seront envoyées au backend via une API REST sécurisée (HTTPS). L'utilisation de WebSockets sera envisagée pour une communication plus réactive et en temps réel.

2.2. Backend (Serveur Applicatif)
Langage/Framework : Python avec le framework FastAPI. Python est l'écosystème de choix pour l'IA, et FastAPI est moderne, extrêmement performant et simple à utiliser pour créer des API.

Rôle d'Orchestrateur : Le backend est le chef d'orchestre. À chaque message de l'utilisateur, il exécute le processus suivant :

Recevoir la requête de l'utilisateur (texte ou audio transcrit).

Convertir la requête en vecteur (embedding).

Interroger la Base de Données Vectorielle pour trouver les N passages les plus pertinents dans la mémoire de l'utilisateur (RAG - Retrieval-Augmented Generation).

Construire un "méga-prompt" contenant la requête initiale et le contexte récupéré.

Envoyer ce prompt au service LLM externe.

Recevoir la réponse du LLM.

La sauvegarder dans l'historique de conversation.

La renvoyer à l'application frontend.

2.3. Serveur de Données & Base de Données Vectorielle
Stockage des Données Brutes : Un dossier surveillé sur un serveur personnel (un NAS Synology, un Raspberry Pi 4/5, ou un simple ordinateur dédié). C'est là que les exports WhatsApp, les fichiers audio du journal, etc., seront déposés.

Pipeline de Traitement des Données (ETL) : Un script Python autonome qui s'exécute en continu ou à intervalles réguliers sur le serveur personnel.

Détection : Surveille l'arrivée de nouveaux fichiers dans le dossier de stockage.

Extraction & Transformation :

Pour les fichiers audio (.mp3, .m4a) : Transcription en texte via un modèle local comme Whisper d'OpenAI.

Pour les fichiers texte (.txt, .md, exports de chat) : Nettoyage et segmentation du texte en petits morceaux (chunks) de taille cohérente (ex: 200-300 mots).

Chargement & Vectorisation (Loading & Embedding) :

Chaque morceau de texte est transformé en un vecteur numérique à l'aide d'un modèle d'embedding (ex: all-MiniLM-L6-v2 de Sentence-Transformers, qui peut tourner localement).

Base de Données Vectorielle : ChromaDB. C'est une solution open-source, parfaite pour un projet personnel car elle peut être auto-hébergée facilement sur le même serveur que les données, sans coût externe. Elle stockera les vecteurs et permettra une recherche sémantique ultra-rapide.

2.4. Service de Modèle de Langage (LLM)
Modèle : GPT-4o d'OpenAI ou Claude 3 Opus d'Anthropic. Ces modèles sont à la pointe en termes de compréhension du langage, de raisonnement et de capacités conversationnelles. Le choix final se fera après des tests de performance et de pertinence des réponses pour le cas d'usage de Pegasus.

Interaction : La communication se fera via l'API officielle du fournisseur. La qualité des prompts envoyés par le backend sera cruciale.

3. Sécurité, Confidentialité et Déploiement
Authentification : L'accès à l'application se fera via un système d'authentification privé et robuste. Le lien entre l'application et le backend sera sécurisé par un token JWT (JSON Web Token).

Chiffrement :

En Transit : Communication systématiquement en HTTPS (TLS 1.3).

Au Repos : Les données sur le serveur personnel devront être sur un disque chiffré.

Clés d'API : Les clés d'accès au service LLM seront stockées de manière sécurisée dans les variables d'environnement du backend, jamais dans le code source ou sur le frontend.

Infrastructure :

Serveur Personnel : Un mini-ordinateur (Raspberry Pi 5, Intel NUC) est suffisant pour héberger le serveur de données, le pipeline de traitement et ChromaDB.

Backend : Peut être hébergé sur le même serveur personnel via Docker pour la simplicité, ou sur une petite instance cloud privée (ex: DigitalOcean, Scaleway) pour une meilleure disponibilité.

4. Prochaines Étapes Techniques
Mise en place du serveur personnel : Installation du système d'exploitation et de Docker.

Développement d'un POC (Proof of Concept) : Créer le script Python qui surveille un dossier, transcrit un fichier audio avec Whisper, le vectorise et l'insère dans ChromaDB. C'est l'étape la plus critique.

Développement de l'API Backend : Créer un endpoint /chat qui simule l'orchestration sans encore être connecté au frontend.

Développement de l'interface de chat sur React Native.