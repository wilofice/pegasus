ChatResponse(response="That's great. I'm here to listen whenever you're ready to share. Please take your time, and tell me what's on your mind or what happened today.", session_id='f3ef49a2-a24b-41ca-be2e-cc0c1bd08bcd', config=ChatConfig(max_context_results=15, aggregation_strategy=<AggregationStrategy.ENSEMBLE: 'ensemble'>, ranking_strategy=<RankingStrategy.ENSEMBLE: 'ensemble'>, conversation_mode=<ConversationMode.STANDARD: 'standard'>, response_style=<ResponseStyle.PROFESSIONAL: 'professional'>, include_sources=True, include_confidence=False, use_local_llm=False, llm_model='gpt-3.5-turbo', max_tokens=1000, temperature=0.7, enable_plugins=True, plugin_timeout=5.0, context_timeout=10.0, total_timeout=30.0), metrics=ChatMetrics(context_retrieval_time_ms=215.795, llm_generation_time_ms=5419.356, plugin_processing_time_ms=0.064, total_processing_time_ms=5646.448, context_results_count=0, top_context_score=0.0, plugins_executed=[], confidence_score=0.5), context_used=AggregatedContext(results=[], query='ok I will tell you about it', config=AggregationConfig(strategy=<AggregationStrategy.ENSEMBLE: 'ensemble'>, max_results=15, vector_weight=0.7, graph_weight=0.3, include_related=True, deduplication_enabled=True, similarity_threshold=0.1, ranking_strategy=<RankingStrategy.ENSEMBLE: 'ensemble'>, ranking_weights=None, timeout_seconds=30.0, parallel_retrieval=True, traversal_depth=2), metrics=AggregationMetrics(total_retrieval_time_ms=211.91899999999998, total_ranking_time_ms=0.007, total_processing_time_ms=212.03, vector_results_count=0, graph_results_count=0, final_results_count=0, duplicates_removed=0, strategy_used='ensemble', ranking_strategy_used='ensemble'), metadata={'user_id': None, 'timestamp': '2025-07-09T23:08:21.759875', 'filters_applied': 0, 'retrievers_used': ['chromadb', 'neo4j']}), sources=[], suggestions=['Tell me more about that.'], metadata={})